{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T06:22:56.749470Z",
     "start_time": "2019-02-22T06:22:56.746765Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T06:23:05.568004Z",
     "start_time": "2019-02-22T06:23:05.565446Z"
    }
   },
   "outputs": [],
   "source": [
    "class_num = 10\n",
    "image_size = 32\n",
    "img_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T06:24:41.375217Z",
     "start_time": "2019-02-22T06:24:41.372388Z"
    }
   },
   "outputs": [],
   "source": [
    "# ========================================================== #\n",
    "# ├─ prepare_data()\n",
    "#  ├─ download training data if not exist by download_data()\n",
    "#  ├─ load data by load_data()\n",
    "#  └─ shuffe and return data\n",
    "# ========================================================== #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T06:23:18.812033Z",
     "start_time": "2019-02-22T06:23:18.806038Z"
    }
   },
   "outputs": [],
   "source": [
    "def download_data():\n",
    "    dirname = 'cifar-10-batches-py'\n",
    "    origin = 'http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
    "    fname = 'cifar-10-python.tar.gz'\n",
    "    fpath = './' + dirname\n",
    "\n",
    "    download = False\n",
    "    if os.path.exists(fpath) or os.path.isfile(fname):\n",
    "        download = False\n",
    "        print(\"DataSet aready exist!\")\n",
    "    else:\n",
    "        download = True\n",
    "    if download:\n",
    "        print('Downloading data from', origin)\n",
    "        import urllib.request\n",
    "        import tarfile\n",
    "\n",
    "        def reporthook(count, block_size, total_size):\n",
    "            global start_time\n",
    "            if count == 0:\n",
    "                start_time = time.time()\n",
    "                return\n",
    "            duration = time.time() - start_time\n",
    "            progress_size = int(count * block_size)\n",
    "            speed = int(progress_size / (1024 * duration))\n",
    "            percent = min(int(count * block_size * 100 / total_size), 100)\n",
    "            sys.stdout.write(\"\\r...%d%%, %d MB, %d KB/s, %d seconds passed\" %\n",
    "                             (percent, progress_size / (1024 * 1024), speed, duration))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        urllib.request.urlretrieve(origin, fname, reporthook)\n",
    "        print('Download finished. Start extract!', origin)\n",
    "        if (fname.endswith(\"tar.gz\")):\n",
    "            tar = tarfile.open(fname, \"r:gz\")\n",
    "            tar.extractall()\n",
    "            tar.close()\n",
    "        elif (fname.endswith(\"tar\")):\n",
    "            tar = tarfile.open(fname, \"r:\")\n",
    "            tar.extractall()\n",
    "            tar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T06:23:26.966273Z",
     "start_time": "2019-02-22T06:23:26.963502Z"
    }
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T06:23:33.625442Z",
     "start_time": "2019-02-22T06:23:33.622586Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data_one(file):\n",
    "    batch = unpickle(file)\n",
    "    data = batch[b'data']\n",
    "    labels = batch[b'labels']\n",
    "    print(\"Loading %s : %d.\" % (file, len(data)))\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T06:23:42.896219Z",
     "start_time": "2019-02-22T06:23:42.892073Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(files, data_dir, label_count):\n",
    "    global image_size, img_channels\n",
    "    data, labels = load_data_one(data_dir + '/' + files[0])\n",
    "    for f in files[1:]:\n",
    "        data_n, labels_n = load_data_one(data_dir + '/' + f)\n",
    "        data = np.append(data, data_n, axis=0)\n",
    "        labels = np.append(labels, labels_n, axis=0)\n",
    "    labels = np.array([[float(i == label) for i in range(label_count)] for label in labels])\n",
    "    data = data.reshape([-1, img_channels, image_size, image_size])\n",
    "    data = data.transpose([0, 2, 3, 1])\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T06:23:51.706434Z",
     "start_time": "2019-02-22T06:23:51.701604Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    print(\"======Loading data======\")\n",
    "    download_data()\n",
    "    data_dir = './cifar-10-batches-py'\n",
    "    image_dim = image_size * image_size * img_channels\n",
    "    meta = unpickle(data_dir + '/batches.meta')\n",
    "\n",
    "    label_names = meta[b'label_names']\n",
    "    label_count = len(label_names)\n",
    "    train_files = ['data_batch_%d' % d for d in range(1, 6)]\n",
    "    train_data, train_labels = load_data(train_files, data_dir, label_count)\n",
    "    test_data, test_labels = load_data(['test_batch'], data_dir, label_count)\n",
    "\n",
    "    print(\"Train data:\", np.shape(train_data), np.shape(train_labels))\n",
    "    print(\"Test data :\", np.shape(test_data), np.shape(test_labels))\n",
    "    print(\"======Load finished======\")\n",
    "\n",
    "    print(\"======Shuffling data======\")\n",
    "    indices = np.random.permutation(len(train_data))\n",
    "    train_data = train_data[indices]\n",
    "    train_labels = train_labels[indices]\n",
    "    print(\"======Prepare Finished======\")\n",
    "\n",
    "    return train_data, train_labels, test_data, test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T06:23:59.443532Z",
     "start_time": "2019-02-22T06:23:59.441231Z"
    }
   },
   "outputs": [],
   "source": [
    "# ========================================================== #\n",
    "# ├─ _random_crop()\n",
    "# ├─ _random_flip_leftright()\n",
    "# ├─ data_augmentation()\n",
    "# └─ color_preprocessing()\n",
    "# ========================================================== #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T06:24:06.511012Z",
     "start_time": "2019-02-22T06:24:06.506318Z"
    }
   },
   "outputs": [],
   "source": [
    "def _random_crop(batch, crop_shape, padding=None):\n",
    "    oshape = np.shape(batch[0])\n",
    "\n",
    "    if padding:\n",
    "        oshape = (oshape[0] + 2 * padding, oshape[1] + 2 * padding)\n",
    "    new_batch = []\n",
    "    npad = ((padding, padding), (padding, padding), (0, 0))\n",
    "    for i in range(len(batch)):\n",
    "        new_batch.append(batch[i])\n",
    "        if padding:\n",
    "            new_batch[i] = np.lib.pad(batch[i], pad_width=npad,\n",
    "                                      mode='constant', constant_values=0)\n",
    "        nh = random.randint(0, oshape[0] - crop_shape[0])\n",
    "        nw = random.randint(0, oshape[1] - crop_shape[1])\n",
    "        new_batch[i] = new_batch[i][nh:nh + crop_shape[0],\n",
    "                       nw:nw + crop_shape[1]]\n",
    "    return new_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T06:24:13.710112Z",
     "start_time": "2019-02-22T06:24:13.707156Z"
    }
   },
   "outputs": [],
   "source": [
    "def _random_flip_leftright(batch):\n",
    "    for i in range(len(batch)):\n",
    "        if bool(random.getrandbits(1)):\n",
    "            batch[i] = np.fliplr(batch[i])\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T06:24:20.654523Z",
     "start_time": "2019-02-22T06:24:20.649123Z"
    }
   },
   "outputs": [],
   "source": [
    "def color_preprocessing(x_train, x_test):\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train[:, :, :, 0] = (x_train[:, :, :, 0] - np.mean(x_train[:, :, :, 0])) / np.std(x_train[:, :, :, 0])\n",
    "    x_train[:, :, :, 1] = (x_train[:, :, :, 1] - np.mean(x_train[:, :, :, 1])) / np.std(x_train[:, :, :, 1])\n",
    "    x_train[:, :, :, 2] = (x_train[:, :, :, 2] - np.mean(x_train[:, :, :, 2])) / np.std(x_train[:, :, :, 2])\n",
    "\n",
    "    x_test[:, :, :, 0] = (x_test[:, :, :, 0] - np.mean(x_test[:, :, :, 0])) / np.std(x_test[:, :, :, 0])\n",
    "    x_test[:, :, :, 1] = (x_test[:, :, :, 1] - np.mean(x_test[:, :, :, 1])) / np.std(x_test[:, :, :, 1])\n",
    "    x_test[:, :, :, 2] = (x_test[:, :, :, 2] - np.mean(x_test[:, :, :, 2])) / np.std(x_test[:, :, :, 2])\n",
    "\n",
    "    return x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T06:24:27.165757Z",
     "start_time": "2019-02-22T06:24:27.162766Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_augmentation(batch):\n",
    "    batch = _random_flip_leftright(batch)\n",
    "    batch = _random_crop(batch, [32, 32], 4)\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T08:21:35.258208Z",
     "start_time": "2019-02-22T08:21:35.255296Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#from tflearn.layers.conv import global_avg_pool\n",
    "from tensorflow.contrib.layers import batch_norm, flatten\n",
    "from tensorflow.contrib.layers import xavier_initializer\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "tf.reset_default_graph()\n",
    "#from cifar10 import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T07:23:36.341360Z",
     "start_time": "2019-02-22T07:23:36.337779Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "growth_k = 24\n",
    "nb_block = 2 # how many (dense block + Transition Layer) ?\n",
    "#init_learning_rate = 1e-4 # AdamOptimizer epsilon\n",
    "\n",
    "epsilon = 1e-4 # AdamOptimizer epsilon\n",
    "dropout_rate = 0.2\n",
    "\n",
    "# Momentum Optimizer will use\n",
    "nesterov_momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "init_learning_rate = 0.1\n",
    "\n",
    "# Label & batch_size\n",
    "batch_size = 64\n",
    "\n",
    "iteration = 782\n",
    "# batch_size * iteration = data_set_number\n",
    "\n",
    "test_iteration = 10\n",
    "\n",
    "total_epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T07:23:38.266006Z",
     "start_time": "2019-02-22T07:23:38.261199Z"
    }
   },
   "outputs": [],
   "source": [
    "def Evaluate(sess):\n",
    "    test_acc = 0.0\n",
    "    test_loss = 0.0\n",
    "    \n",
    "    \n",
    "    for it in range(test_iteration):\n",
    "\n",
    "        test_feed_dict = {\n",
    "            handle: test_handle,\n",
    "            learning_rate: epoch_learning_rate,\n",
    "            training_flag: False\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            loss_, acc_ = sess.run([cost, accuracy], feed_dict=test_feed_dict)\n",
    "        \n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"End of append test.\")\n",
    "\n",
    "        test_loss += loss_ / 10.0\n",
    "        test_acc += acc_ / 10.0\n",
    "\n",
    "    summary = tf.Summary(value=[tf.Summary.Value(tag='test_loss', simple_value=test_loss),\n",
    "                                tf.Summary.Value(tag='test_accuracy', simple_value=test_acc)])\n",
    "\n",
    "    return test_acc, test_loss, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T07:23:42.387645Z",
     "start_time": "2019-02-22T07:23:42.380333Z"
    }
   },
   "outputs": [],
   "source": [
    "def conv_layer(input, filter, kernel, stride=1, layer_name=\"conv\"):\n",
    "    with tf.name_scope(layer_name):\n",
    "        network = tf.layers.conv2d(inputs=input, use_bias=True, filters=filter, kernel_size=kernel, strides=stride, padding='SAME')\n",
    "        return network\n",
    "    \n",
    "def global_avg_pool(x, name='global_avg_pool', data_format='NHWC'):\n",
    "    assert x.shape.ndims == 4\n",
    "    assert data_format in ['NHWC', 'NCHW']\n",
    "    with tf.name_scope(name):\n",
    "        axis = [1, 2] if data_format == 'NHWC' else [2, 3]\n",
    "        return tf.reduce_mean(x, axis)\n",
    "\n",
    "def Global_Average_Pooling(x, stride=1):\n",
    "\n",
    "    return global_avg_pool(x, name='Global_avg_pooling')\n",
    "\n",
    "def Drop_out(x, rate, training) :\n",
    "    return tf.layers.dropout(inputs=x, rate=rate, training=training)\n",
    "\n",
    "def Relu(x):\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def Average_pooling(x, pool_size=[2,2], stride=2, padding='VALID'):\n",
    "    return tf.layers.average_pooling2d(inputs=x, pool_size=pool_size, strides=stride, padding=padding)\n",
    "\n",
    "\n",
    "def Max_Pooling(x, pool_size=[3,3], stride=2, padding='VALID'):\n",
    "    return tf.layers.max_pooling2d(inputs=x, pool_size=pool_size, strides=stride, padding=padding)\n",
    "\n",
    "def Concatenation(layers) :\n",
    "    return tf.concat(layers, axis=3)\n",
    "\n",
    "def Linear(x) :\n",
    "    return tf.layers.dense(inputs=x, units=class_num, name='linear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T08:29:58.744213Z",
     "start_time": "2019-02-22T08:29:58.732889Z"
    }
   },
   "outputs": [],
   "source": [
    "class DenseNet():\n",
    "    def __init__(self, x, nb_blocks, filters, training):\n",
    "        self.nb_blocks = nb_blocks\n",
    "        self.filters = filters\n",
    "        self.training = training\n",
    "        self.model = self.Dense_net(x)\n",
    "\n",
    "\n",
    "    def bottleneck_layer(self, x, scope):\n",
    "        # print(x)\n",
    "        with tf.name_scope(scope):\n",
    "            #x = Batch_Normalization(x, training=self.training, scope=scope+'_batch1')\n",
    "            #x = tf.layers.batch_normalization(x, training=self.training)\n",
    "            x = tf.contrib.layers.batch_norm(x, scale=True, is_training=self.training, updates_collections=None)\n",
    "            x = Relu(x)\n",
    "            x = conv_layer(x, filter=4 * self.filters, kernel=[1,1], layer_name=scope+'_conv1')\n",
    "            x = Drop_out(x, rate=dropout_rate, training=self.training)\n",
    "\n",
    "            #x = Batch_Normalization(x, training=self.training, scope=scope+'_batch2')\n",
    "            #x = tf.layers.batch_normalization(x, training=self.training)\n",
    "            x = tf.contrib.layers.batch_norm(x, scale=True, is_training=self.training, updates_collections=None)\n",
    "            x = Relu(x)\n",
    "            x = conv_layer(x, filter=self.filters, kernel=[3,3], layer_name=scope+'_conv2')\n",
    "            x = Drop_out(x, rate=dropout_rate, training=self.training)\n",
    "\n",
    "            # print(x)\n",
    "\n",
    "            return x\n",
    "\n",
    "    def transition_layer(self, x, scope):\n",
    "        with tf.name_scope(scope):\n",
    "            #x = Batch_Normalization(x, training=self.training, scope=scope+'_batch1')\n",
    "            #x = tf.layers.batch_normalization(x, training=self.training)\n",
    "            x = tf.contrib.layers.batch_norm(x, scale=True, is_training=self.training, updates_collections=None)\n",
    "            x = Relu(x)\n",
    "            shape = x.get_shape().as_list()\n",
    "            in_channel = shape[3]\n",
    "            #x = conv_layer(x, filter=self.filters, kernel=[1,1], layer_name=scope+'_conv1')\n",
    "            x = conv_layer(x, filter=in_channel*0.5, kernel=[1,1], layer_name=scope+'_conv1')\n",
    "            x = Drop_out(x, rate=dropout_rate, training=self.training)\n",
    "            x = Average_pooling(x, pool_size=[2,2], stride=2)\n",
    "\n",
    "            return x\n",
    "\n",
    "        \n",
    "    def dense_block(self, input_x, nb_layers, layer_name):\n",
    "        with tf.name_scope(layer_name):\n",
    "            layers_concat = list()\n",
    "            layers_concat.append(input_x)\n",
    "            #print(input_x.shape)\n",
    "            x = self.bottleneck_layer(input_x, scope=layer_name + '_bottleN_' + str(0))\n",
    "            #print(\"after:\",input_x.shape)\n",
    "            layers_concat.append(x)\n",
    "\n",
    "            for i in range(nb_layers - 1):\n",
    "                x = Concatenation(layers_concat)\n",
    "                x = self.bottleneck_layer(x, scope=layer_name + '_bottleN_' + str(i + 1))\n",
    "                layers_concat.append(x)\n",
    "\n",
    "            x = Concatenation(layers_concat)\n",
    "\n",
    "            return x\n",
    "\n",
    "    def Dense_net(self, input_x):\n",
    "        x = conv_layer(input_x, filter=16, kernel=[3,3], stride=1, layer_name='conv0')\n",
    "        #x = Max_Pooling(x, pool_size=[3,3], stride=2)\n",
    "\n",
    "        x = self.dense_block(input_x=x, nb_layers=3, layer_name='dense_1')\n",
    "        x = self.transition_layer(x, scope='trans_1')\n",
    "\n",
    "        x = self.dense_block(input_x=x, nb_layers=3, layer_name='dense_2')\n",
    "        x = self.transition_layer(x, scope='trans_2')\n",
    "        \n",
    "        x = self.dense_block(input_x=x, nb_layers=3, layer_name='dense_final')\n",
    "\n",
    "\n",
    "\n",
    "        # 100 Layer\n",
    "        #x = Batch_Normalization(x, training=self.training, scope='linear_batch')\n",
    "        #x = tf.layers.batch_normalization(x, training=self.training)\n",
    "        x = tf.contrib.layers.batch_norm(x, scale=True, is_training=self.training, updates_collections=None)\n",
    "        x = Relu(x)\n",
    "        x = Global_Average_Pooling(x)\n",
    "        x = flatten(x)\n",
    "        x = Linear(x)\n",
    "\n",
    "\n",
    "        # x = tf.reshape(x, [-1, 10])\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T08:30:32.468348Z",
     "start_time": "2019-02-22T08:30:02.009242Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Loading data======\n",
      "DataSet aready exist!\n",
      "Loading ./cifar-10-batches-py/data_batch_1 : 10000.\n",
      "Loading ./cifar-10-batches-py/data_batch_2 : 10000.\n",
      "Loading ./cifar-10-batches-py/data_batch_3 : 10000.\n",
      "Loading ./cifar-10-batches-py/data_batch_4 : 10000.\n",
      "Loading ./cifar-10-batches-py/data_batch_5 : 10000.\n",
      "Loading ./cifar-10-batches-py/test_batch : 10000.\n",
      "Train data: (50000, 32, 32, 3) (50000, 10)\n",
      "Test data : (10000, 32, 32, 3) (10000, 10)\n",
      "======Load finished======\n",
      "======Shuffling data======\n",
      "======Prepare Finished======\n"
     ]
    }
   ],
   "source": [
    "#tf.reset_default_graph()\n",
    "train_x, train_y, test_x, test_y = prepare_data()\n",
    "train_x, test_x = color_preprocessing(train_x, test_x)\n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
    "train_dataset = train_dataset.batch(64)\n",
    "train_dataset = train_dataset.prefetch(64)\n",
    "train_dataset = train_dataset.repeat(300)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y))\n",
    "test_dataset = test_dataset.batch(1000)\n",
    "test_dataset = test_dataset.prefetch(1000)\n",
    "#extra_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
    "#extra_dataset = extra_dataset.batch(64)\n",
    "\n",
    "handle = tf.placeholder(tf.string, [])\n",
    "feed_iterator = tf.data.Iterator.from_string_handle(handle, train_dataset.output_types,\n",
    "                                                      train_dataset.output_shapes)\n",
    "images, labels = feed_iterator.get_next()\n",
    "\n",
    "train_iterator = train_dataset.make_one_shot_iterator()\n",
    "test_iterator = test_dataset.make_initializable_iterator()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# image_size = 32, img_channels = 3, class_num = 10 in cifar10\n",
    "\n",
    "training_flag = tf.placeholder(tf.bool)\n",
    "learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "\n",
    "logits = DenseNet(x=images, nb_blocks=nb_block, filters=growth_k, training=training_flag).model\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logits))\n",
    "\n",
    "l2_loss = tf.add_n([tf.nn.l2_loss(var) for var in tf.trainable_variables()])\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=nesterov_momentum, use_nesterov=True)\n",
    "train = optimizer.minimize(cost + l2_loss * weight_decay)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "#saver = tf.train.Saver(tf.global_variables())\n",
    "init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258420\n"
     ]
    }
   ],
   "source": [
    "total = np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T08:12:06.588512Z",
     "start_time": "2019-02-22T07:24:34.660668Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73dedc2a7f1040e9b7b9f64095fe190e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/300, train_loss: 1.3842, train_acc: 0.4948, test_loss: 2.7945, test_acc: 0.2820 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f64e7dc98fc4eb38b9201366b9e1a1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/300, train_loss: 0.9860, train_acc: 0.6466, test_loss: 1.5853, test_acc: 0.4731 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03b8db02d282468494871816444855ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/300, train_loss: 0.8638, train_acc: 0.6911, test_loss: 1.6244, test_acc: 0.4634 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "224a1df778284907bb5661742b90ff1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/300, train_loss: 0.7842, train_acc: 0.7227, test_loss: 1.5362, test_acc: 0.5334 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b92f3f5bcec84651b49abbb09c5a8d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5/300, train_loss: 0.7261, train_acc: 0.7435, test_loss: 1.0918, test_acc: 0.6226 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf89b54f41fe46ca88c4a5b9a83eb310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6/300, train_loss: 0.6759, train_acc: 0.7630, test_loss: 1.1351, test_acc: 0.6188 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66942be9e04a46148a3d4ed2dea77902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7/300, train_loss: 0.6374, train_acc: 0.7780, test_loss: 1.5238, test_acc: 0.5129 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d7659f527754ffc96afe93acc8c62e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8/300, train_loss: 0.6086, train_acc: 0.7895, test_loss: 1.1479, test_acc: 0.6062 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cd75a785cc14150a4a64e83844056e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9/300, train_loss: 0.5842, train_acc: 0.7982, test_loss: 0.7982, test_acc: 0.7297 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9de02de18d7a4b9d8e9be0e5bedd4f15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10/300, train_loss: 0.5626, train_acc: 0.8060, test_loss: 1.0913, test_acc: 0.6371 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520cd39c76304c28a4ef01d9a13bef90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11/300, train_loss: 0.5498, train_acc: 0.8093, test_loss: 1.1459, test_acc: 0.6272 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f5c9f451d6a4ae2aac822d786a65d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12/300, train_loss: 0.5369, train_acc: 0.8150, test_loss: 1.0684, test_acc: 0.6360 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb0e307764b543bdb27643d88ba14b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13/300, train_loss: 0.5236, train_acc: 0.8179, test_loss: 1.1938, test_acc: 0.6578 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb91adbe351e402485080ea34ffc9693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14/300, train_loss: 0.5134, train_acc: 0.8217, test_loss: 0.7646, test_acc: 0.7480 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1d2ed7a31314e4a94ea27e2c6c933cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15/300, train_loss: 0.5071, train_acc: 0.8232, test_loss: 1.6980, test_acc: 0.5954 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec23761c6eb246c281cc67b20038aaa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16/300, train_loss: 0.4998, train_acc: 0.8260, test_loss: 1.2222, test_acc: 0.6258 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2dd4fc0815c46c781d3f22f73e817f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17/300, train_loss: 0.4945, train_acc: 0.8276, test_loss: 1.0058, test_acc: 0.6849 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "071f6640eea044e7a17c994336ba9512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18/300, train_loss: 0.4840, train_acc: 0.8334, test_loss: 1.1102, test_acc: 0.6922 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6406d106637c4544b5fc5c74a5a30bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19/300, train_loss: 0.4814, train_acc: 0.8321, test_loss: 0.7363, test_acc: 0.7548 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7907a1dad17e44fc9cc6e4fc9a28c25f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20/300, train_loss: 0.4749, train_acc: 0.8353, test_loss: 0.9288, test_acc: 0.7012 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de2864aa43b74aa08c3a380f4a7f9284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21/300, train_loss: 0.4700, train_acc: 0.8362, test_loss: 1.0667, test_acc: 0.6577 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ce6df9961644949a5022cbf13c2106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22/300, train_loss: 0.4648, train_acc: 0.8382, test_loss: 1.5245, test_acc: 0.5965 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a83948becf4e28bc90c58aab5bf4a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23/300, train_loss: 0.4611, train_acc: 0.8384, test_loss: 0.7736, test_acc: 0.7587 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f535b588bcf4ffd9c0ef91a7ffda773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24/300, train_loss: 0.4528, train_acc: 0.8437, test_loss: 0.9119, test_acc: 0.7211 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e29a20c250a47b891c39172b4b171d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25/300, train_loss: 0.4519, train_acc: 0.8420, test_loss: 0.7138, test_acc: 0.7561 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23d472faf764cf2bb872bdb29a969cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26/300, train_loss: 0.4491, train_acc: 0.8455, test_loss: 0.8062, test_acc: 0.7237 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6166b7f0c9e84a95b7ed78174ccbaa4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27/300, train_loss: 0.4462, train_acc: 0.8445, test_loss: 0.9371, test_acc: 0.7259 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef1237ba19047bba8dca8a17dc04aa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28/300, train_loss: 0.4436, train_acc: 0.8458, test_loss: 1.3961, test_acc: 0.6169 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2efe22824ead4c7eb0cda6de5db4457d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29/300, train_loss: 0.4407, train_acc: 0.8456, test_loss: 1.3163, test_acc: 0.6157 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5204bac4001741848044bf6d985aad77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30/300, train_loss: 0.4330, train_acc: 0.8513, test_loss: 0.7257, test_acc: 0.7548 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1415ade41bb14f84a3480d477b626d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31/300, train_loss: 0.4359, train_acc: 0.8471, test_loss: 0.8966, test_acc: 0.6941 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1d76b5eeb754ce586a64e3ac7f1dfe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32/300, train_loss: 0.4319, train_acc: 0.8495, test_loss: 2.0550, test_acc: 0.5236 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5bad547f3224880a6b5dd589765adbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 33/300, train_loss: 0.4292, train_acc: 0.8493, test_loss: 0.6600, test_acc: 0.7826 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5105e9cc64f24e13acdd6fb827faa64d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 34/300, train_loss: 0.4254, train_acc: 0.8518, test_loss: 0.6819, test_acc: 0.7803 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c09b80ce64a4325a8eacfc961947899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35/300, train_loss: 0.4255, train_acc: 0.8509, test_loss: 0.8433, test_acc: 0.7369 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3d3b220d10a4d619f731a7f82f617fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-165-dd1d4665af12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m                                                   tf.Summary.Value(tag='train_accuracy', simple_value=train_acc)])\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                 \u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_summary\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mEvaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0msummary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_summary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-160-a0d3d6ccfbd8>\u001b[0m in \u001b[0;36mEvaluate\u001b[0;34m(sess)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mloss_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_feed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/apps/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/apps/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/apps/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/apps/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/apps/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/apps/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True # prevents allocation of all GPU memory\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "#with tf.Session() as sess:\n",
    "    \n",
    "    #ckpt = tf.train.get_checkpoint_state('./model')\n",
    "    #if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "        #saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    #else:\n",
    "    sess.run(init_op)\n",
    "    train_handle = sess.run(train_iterator.string_handle())\n",
    "    test_handle = sess.run(test_iterator.string_handle())\n",
    "\n",
    "    summary_writer = tf.summary.FileWriter('./logs5', sess.graph)\n",
    "\n",
    "    epoch_learning_rate = init_learning_rate\n",
    "        \n",
    "    for epoch in range(1, total_epochs + 1):\n",
    "        if epoch == (total_epochs * 0.5) or epoch == (total_epochs * 0.75):\n",
    "            epoch_learning_rate = epoch_learning_rate / 10\n",
    "\n",
    "        \n",
    "        train_acc = 0.0\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for step in tqdm(range(1, iteration + 1)):\n",
    "            \n",
    "\n",
    "            train_feed_dict = {\n",
    "                handle: train_handle,\n",
    "                learning_rate: epoch_learning_rate,\n",
    "                training_flag : True\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                _, batch_loss, batch_acc= sess.run([train, cost, accuracy], feed_dict=train_feed_dict)\n",
    "                #batch_acc = accuracy.eval(feed_dict=train_feed_dict)\n",
    "                \n",
    "            except tf.errors.OutOfRangeError:\n",
    "                print(\"End of append train.\",step)\n",
    "\n",
    "            train_loss += batch_loss\n",
    "            train_acc += batch_acc\n",
    "\n",
    "\n",
    "            if step == iteration :\n",
    "                \n",
    "                sess.run(test_iterator.initializer)\n",
    "                \n",
    "                train_loss /= iteration # average loss\n",
    "                train_acc /= iteration # average accuracy\n",
    "\n",
    "                train_summary = tf.Summary(value=[tf.Summary.Value(tag='train_loss', simple_value=train_loss),\n",
    "                                                  tf.Summary.Value(tag='train_accuracy', simple_value=train_acc)])\n",
    "\n",
    "                test_acc, test_loss, test_summary= Evaluate(sess)\n",
    "\n",
    "                summary_writer.add_summary(summary=train_summary, global_step=epoch)\n",
    "                summary_writer.add_summary(summary=test_summary, global_step=epoch)\n",
    "                summary_writer.flush()\n",
    "\n",
    "                line = \"epoch: %d/%d, train_loss: %.4f, train_acc: %.4f, test_loss: %.4f, test_acc: %.4f \\n\" % (\n",
    "                    epoch, total_epochs, train_loss, train_acc, test_loss, test_acc)\n",
    "                print(line)\n",
    "\n",
    "                with open('logs5.txt', 'a') as f :\n",
    "                    f.write(line)\n",
    "\n",
    "\n",
    "\n",
    "        #saver.save(sess=sess, save_path='./model/dense.ckpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#progress bar - tqdm\n",
    "#count of params \n",
    "#tf.data "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
